{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BVRzkJYvvww"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "\n",
    "import math\n",
    "import bisect\n",
    "import itertools\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from graphviz import Digraph\n",
    "from scipy.ndimage import shift\n",
    "#import pydot\n",
    "\n",
    "\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "import TransferEntropy as te\n",
    "import K2_utils as K2_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n1Getoki4DUF",
    "outputId": "fc272523-0489-40ec-deb9-51ae07578b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: comando n√£o encontrado\r\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.python.org/pypi/pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_first_diff(df):\n",
    "    '''\n",
    "        Function that applies first difference in a DataFrame. \n",
    "        Returns the DataFrame of the first difference\n",
    "    '''\n",
    "    dist_diff = df.diff()\n",
    "    dist_diff.clip(lower=0, inplace=True)\n",
    "    dist_diff.dropna(inplace=True)\n",
    "    dist_diff.reset_index(drop=True, inplace=True)\n",
    "    dist_diff = dist_diff.astype(int)\n",
    "    \n",
    "    return dist_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9nN9piiG0aC"
   },
   "outputs": [],
   "source": [
    "def get_significante_TEs(df, thresh):\n",
    "    '''\n",
    "        Returns a DataFrame with the most significants Transfer entropies based on a threshold. \n",
    "                Not sginifcant ones are set as zero.\n",
    "        params:\n",
    "            df - DataFrame of computed TransferEntropies\n",
    "            thresh - Threshold of significance\n",
    "    '''\n",
    "    final_df = df.copy()\n",
    "    for row in df.columns:\n",
    "        for col in df.columns:\n",
    "            if df[row][col] < thresh:\n",
    "                final_df[row][col] = 0\n",
    "                \n",
    "    return final_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phi8XuryvvxI"
   },
   "outputs": [],
   "source": [
    "def compute_TE_and_lags_for_DataFrame(dist_df, h, k, l):\n",
    "    '''\n",
    "        Algorithm 1 - Generate graph of transferred entropies and relationship information delays\n",
    "        \n",
    "        Computation of transfer Entropy (TE) for a complete dataframe\n",
    "        Params:\n",
    "            dist_df : DataFrame of the variables to compute Transfer Entropy (TE)\n",
    "            h: Window of time horizon. The TE will be computed varying h from 0 to h, the 'h' who provides\n",
    "                maximum amount of entropy will be choosed by the method, and it will be set as highest transfer\n",
    "                entropy lag\n",
    "            l, k -  time horizons of TE\n",
    "    '''\n",
    "    start = time.process_time()\n",
    "    transEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    lagEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    sigValues =  np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    for i in np.arange(0, dist_df.columns.size):\n",
    "        for j in np.arange(0, dist_df.columns.size):\n",
    "            print('trans ', dist_df.columns[i], dist_df.columns[j])\n",
    "            if(j != i + dist_df.columns.size/2 and j!=i and j != i - dist_df.columns.size/2):\n",
    "                te_result = te.te(k,l,h, dist_df[dist_df.columns[i]], dist_df[dist_df.columns[j]])\n",
    "                transEntropy[i][j] = te_result[0]\n",
    "                lagEntropy[i][j] = te_result[1]\n",
    "                \n",
    "            clear_output()\n",
    "    end = time.process_time()   \n",
    "    \n",
    "    print('Time for the complete computation: ', end - start, ' seconds.')\n",
    "    return [transEntropy, lagEntropy]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cycles(graph):\n",
    "    '''\n",
    "        Algorithm 2 - Removal of Graph Cycles\n",
    "        params:\n",
    "            graph: The graph to remove cycles - (np.Matrix)\n",
    "            \n",
    "    '''\n",
    "    graph_mat = copy.deepcopy(graph)\n",
    "    grafo_ac = np.zeros([len(graph_mat), len(graph_mat)], dtype=float)\n",
    "    ancestrals = [[] for el in np.arange(0, len(graph_mat))]\n",
    "    \n",
    "    max_val = max(graph_mat.flatten().tolist())\n",
    "    print(max_val)\n",
    "    idx_max = np.argmax(graph_mat.flatten().tolist())  \n",
    "\n",
    "    while(max_val > 0):\n",
    "        idx_row = int(np.floor(idx_max)/len(graph_mat))\n",
    "        idx_col = idx_max - len(graph_mat)*idx_row\n",
    "\n",
    "        impossible_nodes = []\n",
    "        if ancestrals[idx_row]:\n",
    "            impossible_nodes = get_node_genealogy(copy.deepcopy(ancestrals),idx_row, [])\n",
    "            if not idx_col in impossible_nodes:\n",
    "                grafo_ac[idx_row, idx_col] = graph_mat[idx_row, idx_col]\n",
    "                ancestrals[idx_col] += [idx_row] \n",
    "        else:\n",
    "            ancestrals[idx_col] += [idx_row]\n",
    "            grafo_ac[idx_row,idx_col] = max_val\n",
    "\n",
    "        graph_mat[idx_row, idx_col] = 0\n",
    "        max_val = max(graph_mat.flatten().tolist())\n",
    "        idx_max = np.argmax(graph_mat.flatten())\n",
    "        \n",
    "        \n",
    "    return grafo_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_genealogy(genealogy, node, new_list):\n",
    "    '''\n",
    "        Algorithm 3 - Get node genealogy\n",
    "        Generate the genealogy of a node-\n",
    "        Params: \n",
    "            genealogy: The node genealogy - (Iniatially empty)\n",
    "            node: The node to compute genealogy \n",
    "            new_list: \n",
    "    '''\n",
    "    if np.all(np.unique(genealogy[node]) == ['x']):\n",
    "        return new_list\n",
    "    \n",
    "    if not node in new_list:\n",
    "        new_list.extend([node])\n",
    "            \n",
    "    if not genealogy[node]:\n",
    "        return new_list\n",
    "    else:\n",
    "        for i,no in enumerate(genealogy[node]):       \n",
    "            idx = no\n",
    "            node_to_list = [genealogy[node][i]]\n",
    "            genealogy[node][i] = 'x'\n",
    "            if no == 'x':\n",
    "                continue\n",
    "            if 'x' in genealogy[no]:\n",
    "                get_node_genealogy(genealogy, idx, new_list)   \n",
    "            elif not genealogy[no]:\n",
    "                new_list.extend(node_to_list)\n",
    "                genealogy[no] = ['x']\n",
    "                continue\n",
    "            else:\n",
    "                new_list.extend(node_to_list)\n",
    "                get_node_genealogy(genealogy, idx, new_list)             \n",
    "        else:\n",
    "            return get_node_genealogy(genealogy, node, new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_common_and_virtual_parents(df,idx, summation, dict_lags, lista, dict_ways):\n",
    "    '''\n",
    "    \n",
    "        Algorithm 4 - Generation of Common and Virtual Parents.\n",
    "        \n",
    "            Given a node, computes the delays and the paths between it and its virtual and common parents\n",
    "            params:\n",
    "                df: The dataframe representing the graph, where weights are the lags,\n",
    "                summation: variable for lag summation\n",
    "                dict_lags: Empty dictionary for storing the lags from the \n",
    "                    paths between a node and its common/virtual parents.\n",
    "                lista: \n",
    "                dict_ways: Empty dictionary for storing the paths between a node and its common/virtual parents,\n",
    "    '''\n",
    "    lista.append(idx)\n",
    "    if np.all(df[idx] == np.zeros(len(df))):\n",
    "        return [dict_lags,dict_ways]\n",
    "    for i,dad_lag in enumerate(df[idx]):\n",
    "        if dad_lag > 0:\n",
    "          \n",
    "            summation += dad_lag\n",
    "            try:\n",
    "                dict_lags[df.columns[i]].append(summation)\n",
    "                dict_ways[df.columns[i]].append(lista)\n",
    "            except:\n",
    "                dict_lags[df.columns[i]] = [summation]\n",
    "                dict_ways[df.columns[i]]= [lista]\n",
    "        \n",
    "            gen_common_and_virtual_parents(df, df.columns[i], \n",
    "                                                       summation, dict_lags, \n",
    "                                                       lista[:], dict_ways)\n",
    "            summation -= dad_lag\n",
    "            \n",
    "    return [dict_lags, dict_ways] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_nodes_parents(nodes, df):\n",
    "    \n",
    "    '''\n",
    "        Algorithm 5 - Ensemble nodes parents.\n",
    "    \n",
    "        \n",
    "        This algorithm compute commons and vitual parents for all the nodes in the nodes list.\n",
    "            It returns a dictionary where for each key is a node and the value is\n",
    "            the path between each node and its parent (common or virtual) along the summation\n",
    "            of the lag from all the path.\n",
    "            \n",
    "        params:\n",
    "            nodes: The list of nodes to compute common and virtual parents\n",
    "            df: The dataframe representing the graph, where weights are the lags\n",
    "    '''\n",
    "    dic = {}\n",
    "    for node in nodes:\n",
    "        df_cp = df.copy()\n",
    "#         if not np.all(mat_cp[node] == np.zeros(len(mat_cp))):\n",
    "        dic[node] = gen_common_and_virtual_parents(df_cp, node, 0, {}, [],{})[0]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_k2_tree_from_lags(dici):\n",
    "    '''\n",
    "        Generate the K2 pre-order based on the dictionary of \n",
    "            lags/paths generated by ensemble_node_parents function\n",
    "        params:\n",
    "             dici: The dictionary with paths/lags from common and virtual parents\n",
    "    '''\n",
    "    tree_k2 = {}\n",
    "    for key_son, value in dici.items():    \n",
    "        if value:\n",
    "            for key_dad, value_dad in value.items():\n",
    "                for i, value in enumerate(value_dad):\n",
    "                    try:\n",
    "                        tree_k2[key_son].append(key_dad+\"-\"+str(i)+\"_\"+str(int(value)))\n",
    "                    except:\n",
    "                        tree_k2[key_son] = [key_dad+\"-\"+str(i)+\"_\"+str(int(value))]\n",
    "\n",
    "                    tree_k2[key_dad+\"-\"+str(i)+\"_\"+str(int(value))] = []\n",
    "        else:\n",
    "            tree_k2[key_son] = []\n",
    "    return tree_k2  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_of_K2_iteration(df, node, dict_lag):\n",
    "    '''\n",
    "        Algorithm 6: 'Generate_dataset_of_K2_iteration'\n",
    "        \n",
    "            This algorithm generate the dataset that will be used in each K2 iteration. \n",
    "            It genrates a shifted dataset according with lag of highest transfer of entropy\n",
    "            \n",
    "            params:\n",
    "                df: \n",
    "                node: Node to compute the dataframe shifted according to Lags\n",
    "                dict_lag: A dictionary with the lags between the node and its parents\n",
    "    '''\n",
    "    df_gen = df.copy()\n",
    "    if dict_lag[node]:\n",
    "        for key_dad, values_dad in dict_lag[node].items():\n",
    "            for i, val in enumerate(dict_lag[node][key_dad]): \n",
    "                df_gen[key_dad+\"-\"+str(i)+\"_\"+str(int(val))] = shift(df_gen[key_dad], int(val), order=0, mode='constant', cval=np.NaN)\n",
    "    df_gen.dropna(inplace=True)\n",
    "    return df_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_of_the_graph(df_lags, k2_return):\n",
    "    '''\n",
    "        Algorithm 8 - Reconstruction of the graph\n",
    "        params:\n",
    "            df_lags - DataFrame with lags of the relationships\n",
    "                (Corresponds to the lags of graph with the most significant entropies and no cycles)\n",
    "            k2_return - Resulting tree delivered by K2-Modified (Dictionary)\n",
    "    \n",
    "    '''\n",
    "    df_clean = pd.DataFrame(data=np.zeros([len(df_lags.columns),len(df_lags.columns)], dtype=float), columns= df_lags.columns, index= df_lags.columns) \n",
    "\n",
    "    for key, values in k2_return.items():\n",
    "        node_son = key\n",
    "        lista_son = te. get_lags_ances_df(df_lags, node_son,0, {}, [], {})[1]\n",
    "\n",
    "        for node in values:\n",
    "            split_name = node.split('-')\n",
    "            node_ref = split_name[0]\n",
    "            lag = split_name[1].split('_')[1]\n",
    "            idx_ref = int(split_name[1].split('_')[0])\n",
    "\n",
    "            count = 0\n",
    "            path_list = lista_son[node_ref][idx_ref][::-1]\n",
    "\n",
    "            if len(lista_son[node_ref][idx_ref][::-1]) == 1:\n",
    "                print('here ',node_ref, node_son)\n",
    "                df_clean.at[node_ref,node_son] = 1\n",
    "            while count < len(path_list) -1:\n",
    "                print('here ',node_ref, node_son)\n",
    "                df_clean.at[path_list[count], path_list[count+1]] = 1\n",
    "                count +=1\n",
    "            if not len(lista_son[node_ref][idx_ref][::-1]) == 1:\n",
    "                df_clean.at[node_ref, path_list[0]] = 1\n",
    "                \n",
    "            df_clean = te_vld__lags_no_cycle[df_clean>0].fillna(0)\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k2_modified(df_cases, dict_lags,tree_ogn, c=1):\n",
    "    \n",
    "    '''K2_modified algorithm implementation\n",
    "    \n",
    "        params:\n",
    "            df_cases: The dataframe of cases of the bayesian network, the columns are all the nodes \n",
    "            of the K2 pre-order \n",
    "            c: A factor for used in the evaluation of MDL score metric. Default = 1, (Optional)\n",
    "    \n",
    "        '''\n",
    "    tree = copy.deepcopy(tree_ogn)\n",
    "    dict_parents = {}\n",
    "    \n",
    "    dfs_list = []\n",
    "      \n",
    "    for col in df_cases.columns:\n",
    "        dfs_list.append(generate_dataset_of_K2_iteration(df_cases, col, dict_lags))\n",
    "    \n",
    "  \n",
    "    sigma = 0\n",
    "    parents = [[] for node in df_cases.columns]\n",
    "   \n",
    "    count = 0\n",
    "    for xi, col in enumerate(df_cases.columns):\n",
    "        \n",
    "        df = dfs_list[count]\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        pold = K2_utils.f_mdl(df_cases, xi, parents[xi], c)\n",
    "    \n",
    "        tree_xi = []\n",
    "        if tree:\n",
    "              tree_xi = tree[col]\n",
    "    \n",
    "        f_ances = []\n",
    "        while (True):\n",
    "            test_parents = [parents[xi]+[ances] for ances in tree_xi] if tree_xi else []            \n",
    "            f_ances = [K2_utils.f_mdl(df, xi,parent,c) for parent in test_parents] if test_parents else [K2_utils.f_mdl(df, xi, test_parents,c)]\n",
    "            \n",
    "            j_max = np.argmax(f_ances)\n",
    "\n",
    "            sigma = f_ances[j_max]> pold\n",
    "        \n",
    "            if sigma:\n",
    "                parents[xi] = parents[xi] + [no for no in [tree_xi[j_max]] if no not in parents[xi]]\n",
    "                pold = f_ances[j_max]\n",
    "  \n",
    "            if tree_xi:\n",
    "                del tree_xi[j_max]\n",
    "      \n",
    "            if(not sigma) or  (not tree_xi):\n",
    "                break\n",
    "        \n",
    "    for i,parent in enumerate(parents):\n",
    "        dict_parents[df_cases.columns[i]] = parent\n",
    "    return dict_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2_mod_result = {}\n",
    "\n",
    "def apply_methodlogy(k,l,h, t, alarms_df):\n",
    "    '''\n",
    "        Application of all the stages of the proposed Method on the case study\n",
    "        params: \n",
    "            df_te - DataFrame with  transfer entropies of the relationships\n",
    "                (Corresponds to the graph with the most significant entropies and no cycles)\n",
    "            df_lags - DataFrame with lags of the relationships\n",
    "                (Corresponds to the lags of graph with the most significant entropies and no cycles)\n",
    "            alarms_df: DataFrame wih the industrial alarms that occurreddue to the disturbance application\n",
    "    '''\n",
    "    global k2_mod_result\n",
    "    \n",
    "    df_te_and_lags = compute_TE_and_lags_for_DataFrame(alarms_df, h, k , l)\n",
    "    \n",
    "    df_te = df_te_and_lags[0]\n",
    "    df_lags = df_te_and_lags[1]\n",
    "    \n",
    "    #Threshold proposed by the article -     t = 0.007668474476869511\n",
    "    \n",
    "    #Apply threshold on DataFrame (graph) of tranfer entropies\n",
    "    te_significants = get_significante_TEs(df_te, t)\n",
    "    \n",
    "    \n",
    "    #Removal of Cycles of graph of TransferEntropies\n",
    "    te_no_cycle = pd.DataFrame(data = remove_cycles(te_significants.values), \n",
    "                                   columns=te_significants.columns, index=te_significants.columns)\n",
    "\n",
    "    # Utilizing the graph containing the lags of the relationships\n",
    "    te_lags_no_cycle = df_lag[te_no_cycle > 0].fillna(0)\n",
    "\n",
    "    #Computing Common and Virtual Parents lags DataFrame\n",
    "    dict_lags = ensemble_nodes_parents(te_lags_no_cycle.columns, te_lags_no_cycle)\n",
    "\n",
    "    #Generation of K2 pre-order\n",
    "    k2_tree = gen_tree_from_lags(dict_parents)\n",
    "\n",
    "    #Computation of Modified K2\n",
    "    k2_mod_result = k2_modified(alarms_df,dict_lags, k2_tree,1)\n",
    "\n",
    "    #Reconstruction of the final graph\n",
    "    final_graph = reconstruction_of_the_graph(te_lags_no_cycle, k2_mod_result)\n",
    "    return final_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TransEntropy.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
